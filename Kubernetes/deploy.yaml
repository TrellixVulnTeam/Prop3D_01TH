apiVersion: batch/v1
kind: Job
metadata:
  # It is good practice to include your username in your job name.
  # Also specify it in TOIL_KUBERNETES_OWNER
  name: molimic-data-generation-toil
# Do not try and rerun the leader job if it fails

spec:
 backoffLimit: 0
 template:
   spec:
     # Do not restart the pod when the job fails, but keep it around so the
     # log can be retrieved
     restartPolicy: Never
     volumes:
     - name: aws-credentials-vol
       secret:
           # Make sure the AWS credentials are available as a volume.
           # This should match TOIL_AWS_SECRET_NAME
           secretName: aws-credentials
     - name: hsds-credentials-vol
       secret:
           # Make sure the AWS credentials are available as a volume.
           # This should match TOIL_AWS_SECRET_NAME
           secretName: hsds-credentials
     # You may need to replace this with a different service account name as
     # appropriate for your cluster.
     serviceAccountName: default
     containers:
     - name: main
       image: edraizen/molmimic:0.0.1
       imagePullPolicy: Never
       env:
       # Specify your username for inclusion in job names
       - name: TOIL_KUBERNETES_OWNER
         value: default
       # Specify where to find the AWS credentials to access the job store with
       - name: TOIL_AWS_SECRET_NAME
         value: aws-credentials
       # Specify where per-host caches should be stored, on the Kubernetes hosts.
       # Needs to be set for Toil's caching to be efficient.
       # - name: TOIL_KUBERNETES_HOST_PATH
       #   value: /home/bournelab/molmimic/Kubernetes/test
       - name: TOIL_WORKDIR
         value: /tmp/scratch
       - name: SINGULARITY_CACHEDIR
         value: /tmp/scratch #This exists in the container
       - name: TOIL_DOCKER_REGISTRY
         value: edraizen
       - name: TOIL_DOCKER_NAME
         value: molmimic
       - name: TOIL_APPLIANCE_SELF
         value: edraizen/molmimic:0.0.1
       - name: JOB_NAME
         value: cath-paper-test-real
       #- name: TOIL_S3_HOST
       #  value: minio.minio-tenant-1.svc.cluster.local
       #- name: TOIL_S3_PORT
       #  value: "80"
       #- name: TOIL_S3_USE_SSL
       #  value: "False"
       #- name: S3_ENDPOINT
       #    value: http://minio.minio-tenant-1.svc.cluster.local:80
       - name: HS_ENDPOINT
         value: http://hsds.default.svc.cluster.local:5101
       - name: USE_SINGULARITY
         value: "True"
       - name: SFAMS
         value: "1.10.10.10 1.10.238.10 1.10.490.10 1.10.510.10 1.20.1260.10 2.30.30.100 2.40.50.140 2.60.40.10 3.10.20.30 3.30.230.10 3.30.300.20 3.30.310.60 3.30.1360.40 3.30.1370.10 3.30.1380.10 3.40.50.300 3.40.50.720 3.80.10.10 3.90.79.10 3.90.420.10"
       volumeMounts:
       # Mount the AWS credentials volume
       - mountPath: /root/.aws
         name: aws-credentials-vol
       - mountPath: /root/.hscfg
         name: hsds-credentials-vol
         subPath: ".hscfg"
       resources:
         # Make sure to set these resource limits to values large enough
         # to accommodate the work your workflow does in the leader
         # process, but small enough to fit on your cluster.
         #
         # Since no request values are specified, the limits are also used
         # for the requests.
         limits:
           cpu: 2
           memory: "4Gi"
           ephemeral-storage: "10Gi"
       command:
       - /bin/bash
       - -c
       - |
         # Test env
         ls -la ~/.aws/
         env | grep TOIL
         # This Bash script will set up Toil and the workflow to run, and run them.
         #set -e
         mkdir -p /root/.cache/aws
         #
         cat ~/.aws/credentials | tail -n 2 | awk '{print $NF}' > /root/.cache/aws/cached_temporary_credentials
         echo "" >> /root/.cache/aws/cached_temporary_credentials
         echo -n "$(date -d '+10 days' +'%Y-%m-%dT%H:%M:%SZ')" >> /root/.cache/aws/cached_temporary_credentials
         cat /root/.cache/aws/cached_temporary_credentials
         wc -l /root/.cache/aws/cached_temporary_credentials
         #
         #
         # Make sure job name is set
         if [[ -z "${JOB_NAME}" ]]; then
             echo "Error! Must set JOB_NAME" 1>&2
             exit 1
         fi
         #
         #Now we increment the job name if there were previous jobs
         export JOB_INDEX=`aws s3 ls | grep $JOB_NAME | wc -l`
         export JOB_FULL_NAME="$JOB_NAME-$JOB_INDEX"
         echo "Running job with name: $JOB_FULL_NAME"
         #
         # Now we run the workflow. We make sure to use the Kubernetes batch
         # system and an AWS job store, and we set some generally useful
         # logging options. We also make sure to enable caching.

         #s3hsds:us-east-1:/home/ed4bu/$JOB_FULL_NAME \

         export

         python -m molmimic.generate_data.main \
             aws:us-east-1:$JOB_FULL_NAME \
             --batchSystem kubernetes \
             --logInfo \
             -c $SFAMS \
             --hsds_file "/home/ed4bu/$JOB_NAME.h5" \
             --force 0 \
             --realTimeLogging \
             --retryCount 4 \
             --clean never \
             --maxNodes 20 \
             --maxLocalJobs 20 \
             --maxCores 4 \
             --maxMemory 10G \
             --stats \
             --setEnv HS_ENDPOINT=$HS_ENDPOINT \
             --setEnv HS_USERNAME=ed4bu@virginia.edu \
             --setEnv HS_PASSWORD=13e571b7f8e41419c63aa7a0f3a33e29 \
             --disableCaching \
